{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework Three\n",
    "\n",
    "## Part One: Decision Trees\n",
    "For this homework, I am taking a look at how team stats can be used as a playoff predictor. To start, I scraped data from the NBA API that featured a teams stats and merged that with data scraped indicating if a team made the plyoffs or not. Note, since the NBA added a Playin tournament in recent years, I had to go back in and manually adjust for teams who made the playoffs through the Playin tournament."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nba_api.stats.endpoints import leaguedashteamstats, leaguestandings\n",
    "team_stats = leaguedashteamstats.LeagueDashTeamStats(season='2023-24').get_data_frames()[0]\n",
    "standings = leaguestandings.LeagueStandings(season='2023-24').get_data_frames()[0]\n",
    "playoff_data = standings[['TeamID', 'ClinchedPlayoffBirth']]\n",
    "merged_data = pd.merge(team_stats, playoff_data, left_on='TEAM_ID', right_on='TeamID')\n",
    "merged_data.loc[\n",
    "    merged_data['TEAM_NAME'].isin(['Los Angeles Lakers', 'New Orleans Pelicans', 'Philadelphia 76ers', 'Miami Heat']),\n",
    "    'ClinchedPlayoffBirth'\n",
    "] = 1\n",
    "merged_data.to_csv(data_file, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, I looked at the basic stats: Points, Rebounds, and Assists (per game): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import numpy as np\n",
    "data_directory = os.path.join(os.path.dirname(os.path.dirname(os.path.dirname(__file__))), 'data', 'teams')\n",
    "data_file = os.path.join(data_directory, 'team_stats_23_24.csv')\n",
    "data = pd.read_csv(data_file)\n",
    "data['PPG'] = data['PTS'] / 82\n",
    "data['RPG'] = data['REB'] / 82\n",
    "data['APG'] = data['AST'] / 82\n",
    "features = ['PPG', 'RPG', 'APG']\n",
    "X = data[features]\n",
    "y = data['ClinchedPlayoffBirth']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "model = DecisionTreeClassifier(criterion='entropy', max_depth=3, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = np.mean(y_pred == y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which yielded: \n",
    "Accuracy: 33.33%\n",
    "Feature Importances: [0.56671216 0.43328784 0.        ]\n",
    "... yikes. But these are very basic stats, it is no wonder they are not a good indicator of playoff stats. Efficiency and defensive stats may be a better place to look.\n",
    "\n",
    "So next, I looked at 3P FG%, Steals per game, and Blocks per game:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(data_file)\n",
    "data['SPG'] = data['STL'] / 82\n",
    "data['BPG'] = data['BLK'] / 82\n",
    "features = ['SPG', 'BPG', 'FG3_PCT']\n",
    "X = data[features]\n",
    "y = data['ClinchedPlayoffBirth']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "model = DecisionTreeClassifier(criterion='entropy', max_depth=4, random_state=42)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which yielded:\n",
    "Accuracy: 83.33%\n",
    "Feature Importances: [0.2218242  0.11536556 0.66281025]\n",
    "\n",
    "Much better (for context 53% of NBA teams make the playoffs). Lets visualize this tree:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10, 6))\n",
    "plot_tree(model, feature_names=features, class_names=[\"No Playoff\", \"Playoff\"], filled=True, rounded=True)\n",
    "plt.title(\"Decision Tree\")\n",
    "data_directory = os.path.join(os.path.dirname(os.path.dirname(os.path.dirname(__file__))), 'visualizations')\n",
    "data_file = os.path.join(data_directory, 'decision_tree_bpg_spg.png')\n",
    "plt.savefig(data_file, dpi=300, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Decision Tree](../visualizations/decision_tree_bpg_spg.png)\n",
    "\n",
    "As you can see from the feature importances, this model weight 3PFG% very heavily, so it may be of interest to replace those with efficiency metrics. I decided to use Effective Field Goal Percentage and Effective Defensive Rating:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['RPG'] = data['REB'] / 82\n",
    "features = ['E_DEF_RATING', 'RPG', 'FG3_PCT']\n",
    "X = data[features]\n",
    "y = data['ClinchedPlayoffBirth']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=30)\n",
    "model = DecisionTreeClassifier(criterion='entropy', max_depth=4, random_state=30)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = np.mean(y_pred == y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which yielded: \n",
    "Accuracy: 83.33%\n",
    "Feature Importances: [0.31516414 0.22689069 0.45794517]\n",
    "Interesting, the model performed with the same accuracy. I think dropping 3PFG% may prove beneficial, as the model seems to latch on to 37% shooting from 3 as the de facto root. So next, I tried replacing 3PFG% with Effective Field Goal Percentage and Rebounds per game with True Shooting Percentage, which yielded:\n",
    "Accuracy: 100.00%\n",
    "Feature Importances: [0.24053414 0.75946586 0.        ]\n",
    "|--- TS_PCT <= 0.57\n",
    "|   |--- class: 0\n",
    "|--- TS_PCT >  0.57\n",
    "|   |--- TS_PCT <= 0.59\n",
    "|   |   |--- E_DEF_RATING <= 111.80\n",
    "|   |   |   |--- class: 1\n",
    "|   |   |--- E_DEF_RATING >  111.80\n",
    "|   |   |   |--- class: 0\n",
    "|   |--- TS_PCT >  0.59\n",
    "|   |   |--- class: 1\n",
    "\n",
    "Oh wow and look at that, 100% only using Defensive Rating and True Shooting Percentage, I think I have found the playoff indicators.\n",
    "\n",
    "### Expanding the Dataset\n",
    "Let's see how this model holds up over the last 5 seasons, I created 5 csv files and ran the model on each of them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for csv_file in csv_files:\n",
    "    data_file = os.path.join(data_directory, csv_file)\n",
    "    data = pd.read_csv(data_file)\n",
    "    \n",
    "    data['PPG'] = data['PTS'] / 82\n",
    "    features = ['E_DEF_RATING', 'TS_PCT', 'EFG_PCT']\n",
    "    X = data[features]\n",
    "    y = data['ClinchedPlayoffBirth']\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=30)\n",
    "    \n",
    "    model = DecisionTreeClassifier(criterion='entropy', max_depth=4, random_state=30)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = np.mean(y_pred == y_test)\n",
    "\n",
    "    feature_importances = model.feature_importances_\n",
    "    \n",
    "    accuracies.append(accuracy * 100)\n",
    "    feature_importances_list.append(feature_importances)\n",
    "    seasons.append(csv_file.split('.')[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And it did not do well, it's accuracy was not good apart from the recent season:\n",
    "![Accuracy](../visualizations/accuracy_over_seasons.png)\n",
    "\n",
    "A look out how features were prioritized:\n",
    "![Features](../visualizations/feature_importances_scatter.png)\n",
    "\n",
    "### One Last Attempt\n",
    "I went back and added points per game to model to see if that made it more consistent (it did not)\n",
    "![Accuracy](../visualizations/accuracy_over_seasons_new.png)\n",
    "\n",
    "## Part Two KNN Clustering\n",
    "I ran a KNN cluster on the same dataset but just looking at True Shooting Percentage and Effective Defensive Rating, since those were the most used features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import os\n",
    "\n",
    "data_directory = os.path.join(os.path.dirname(os.path.dirname(os.path.dirname(__file__))), 'data', 'teams')\n",
    "data_file = os.path.join(data_directory, 'team_stats_23_24.csv')\n",
    "data = pd.read_csv(data_file)\n",
    "\n",
    "features = ['E_DEF_RATING', 'TS_PCT']\n",
    "X = data[features]\n",
    "\n",
    "y = data['ClinchedPlayoffBirth']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "mins = X_train.min(axis=0) - 0.1\n",
    "maxs = X_train.max(axis=0) + 0.1\n",
    "x = np.arange(mins[0], maxs[0], 0.01)\n",
    "y = np.arange(mins[1], maxs[1], 0.01)\n",
    "X_grid, Y_grid = np.meshgrid(x, y)\n",
    "coordinates = np.array([X_grid.ravel(), Y_grid.ravel()]).T\n",
    "\n",
    "color = ('aquamarine', 'bisque', 'lightgrey')\n",
    "cmap = ListedColormap(color)\n",
    "\n",
    "K_vals = [1, 3, 9]\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize=(10, 8), dpi=150, sharex=True, sharey=True)\n",
    "fig.tight_layout()\n",
    "\n",
    "for ax, K in zip(axs.ravel(), K_vals):\n",
    "    knn = KNN(n_neighbors=K)\n",
    "    knn.fit(X_train, y_train)\n",
    "\n",
    "    Z = knn.predict(coordinates)\n",
    "    Z = Z.reshape(X_grid.shape)\n",
    "\n",
    "    # Plot the decision regions\n",
    "    ax.pcolormesh(X_grid, Y_grid, Z, cmap=cmap, shading='nearest')\n",
    "    ax.contour(X_grid, Y_grid, Z, colors='black', linewidths=0.5)\n",
    "\n",
    "    scatter = ax.scatter(X_train[:, 0], X_train[:, 1], c=y_train, cmap='coolwarm', s=40, edgecolors='k')\n",
    "\n",
    "    ax.set_title(f'{K}-NN Decision Regions', fontsize=12)\n",
    "    ax.tick_params(axis='both', labelsize=10)\n",
    "\n",
    "    train_accuracy = knn.score(X_train, y_train)\n",
    "    test_accuracy = knn.score(X_test, y_test)\n",
    "\n",
    "    print('The accuracy for K={} on the train data is {:.3f}'.format(K, test_accuracy))\n",
    "    print('The accuracy for K={} on the test data is {:.3f}'.format(K, test_accuracy))\n",
    "    ax.text(0.05, 0.95, f'Train: {train_accuracy:.3f}\\nTest: {test_accuracy:.3f}',\n",
    "            transform=ax.transAxes, fontsize=10, verticalalignment='top', horizontalalignment='left')\n",
    "\n",
    "\n",
    "visualization_directory = os.path.join(os.path.dirname(os.path.dirname(os.path.dirname(__file__))), 'visualizations')\n",
    "save_file = os.path.join(visualization_directory, 'knn_practice.png')\n",
    "\n",
    "plt.suptitle('Decision Boundaries and Accuracy for k-NN with Different k Values', fontsize=16)\n",
    "plt.xlabel('E_DEF_RATING', fontsize=14)\n",
    "plt.ylabel('TS_PCT', fontsize=14)\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(top=0.9)\n",
    "plt.savefig(save_file)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which generated these returns: \n",
    "The accuracy for K=1 on the train data is 1.000\n",
    "The accuracy for K=1 on the test data is 1.000\n",
    "The accuracy for K=3 on the train data is 0.833\n",
    "The accuracy for K=3 on the test data is 0.833\n",
    "The accuracy for K=9 on the train data is 0.833\n",
    "The accuracy for K=9 on the test data is 0.833\n",
    "\n",
    "*Note I was unable to run for k=27 as there was not 27 nearest neighbors for a dataset of this size.\n",
    "![Decision Regions](../visualizations/knn_practice.png)\n",
    "\n",
    "## SVM\n",
    "Once again using the same dataset, I created an SVM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "import os\n",
    "\n",
    "data_directory = os.path.join(os.path.dirname(os.path.dirname(os.path.dirname(__file__))), 'data', 'teams')\n",
    "data_file = os.path.join(data_directory, 'team_stats_23_24.csv')\n",
    "data = pd.read_csv(data_file)\n",
    "features = ['E_DEF_RATING', 'TS_PCT']\n",
    "X = data[features]\n",
    "y = data['ClinchedPlayoffBirth']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "svm_model = SVC(kernel='linear')\n",
    "svm_model.fit(X_train, y_train)\n",
    "train_accuracy = svm_model.score(X_train, y_train)\n",
    "test_accuracy = svm_model.score(X_test, y_test)\n",
    "\n",
    "print(f\"Training accuracy: {train_accuracy:.3f}\")\n",
    "print(f\"Testing accuracy: {test_accuracy:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which printed:\n",
    "Training accuracy: 0.958\n",
    "Testing accuracy: 0.833\n",
    "\n",
    "And yielded these decision boundaries:\n",
    "![SVM](../visualizations/SVM_practice.png)\n",
    "\n",
    "## Conclusion\n",
    "I took a step back from LeBron this week and focused more on team data. I learned that efficiency metrics are generally better for predicting who will be in the NBA playoffs but that there can be a lot of variation from season to season."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
